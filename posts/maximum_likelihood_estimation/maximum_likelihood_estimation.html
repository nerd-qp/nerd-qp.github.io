<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Why does MLE work?
| Joy Yang</title><link rel=stylesheet href=https://326623.github.io/css/site.min.df3bdd3442672aa286cd5adae1e1ed37de102ef4794aee82a58eae661744c9989d496ba198f45d915b2d383ca2fd6d786a417e2a7cefcafa410c1789214d47d7.css integrity="sha512-3zvdNEJnKqKGzVra4eHtN94QLvR5Su6CpY6uZhdEyZidSWuhmPRdkVstODyi/W14akF+KnzvyvpBDBeJIU1H1w=="><link rel=canonical href=https://326623.github.io/posts/maximum_likelihood_estimation/maximum_likelihood_estimation.html><link rel=alternate type=application/rss+xml href=https://326623.github.io/index.xml title=JoyComputing><meta charset=utf-8><meta http-equiv=x-ua-compatible content="chrome=1"><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><meta name=author content="Joy Yang"><meta name=description content="No title  body { text-align: justify } h5 { display: inline; padding-right: 1em } h6 { display: inline; padding-right: 1em } table { border-collapse: collapse } td { padding: 0.2em; vertical-align: baseline } dt { float: left; min-width: 1.75em; text-align: right; padding-right: 0.75em; font-weight: bold; } dd { margin-left: 2.5em; } .subsup { display: inline; vertical-align: -0.2em } .subsup td { padding: 0px; text-align: left} .fraction { display: inline; vertical-align: -0."><meta property="og:title" content="Why does MLE work?"><meta property="og:description" content="No title  body { text-align: justify } h5 { display: inline; padding-right: 1em } h6 { display: inline; padding-right: 1em } table { border-collapse: collapse } td { padding: 0.2em; vertical-align: baseline } dt { float: left; min-width: 1.75em; text-align: right; padding-right: 0.75em; font-weight: bold; } dd { margin-left: 2.5em; } .subsup { display: inline; vertical-align: -0.2em } .subsup td { padding: 0px; text-align: left} .fraction { display: inline; vertical-align: -0."><meta property="og:type" content="article"><meta property="og:url" content="https://326623.github.io/posts/maximum_likelihood_estimation/maximum_likelihood_estimation.html"><meta property="article:published_time" content="2020-04-14T00:00:00+00:00"><meta property="article:modified_time" content="2020-04-14T00:00:00+00:00"></head><body><nav class="navbar is-transparent" role=navigation aria-label="main navigation"><div class=navbar-brand><a class=navbar-item href=https://326623.github.io/><figure class=image><img alt class=is-rounded src=https://326623.github.io/hhkb_red_esc.jpg></figure></a><a class=navbar-item href=https://326623.github.io/>JoyComputing</a></div><div class=navbar-menu><div class=navbar-start></div><div class=navbar-end><a class=navbar-item href=https://twitter.com/JoyYang11209479 rel=noopener target=_blank><span class=icon><img alt=icons/svg/twitter.svg src=https://326623.github.io/icons/svg/twitter.svg></span></a>
<a class=navbar-item href=https://www.facebook.com/joy.yang.1690671 rel=noopener target=_blank><span class=icon><img alt=icons/svg/facebook.svg src=https://326623.github.io/icons/svg/facebook.svg></span></a>
<a class=navbar-item href=mailto:yangqp5[%20AT%20]outlook.com target=_blank><span class=icon><img alt=email src=https://326623.github.io/icons/svg/email.svg></span></a>
<a class=navbar-item href=https://326623.github.io/index.xml target=_blank><span class=icon><img alt=rss src=https://326623.github.io/icons/svg/rss.svg></span></a></div></div></nav><section class="hero is-small is-info is-fullwidth"><div class=hero-body><div class=container><h1 class=title>Why does MLE work?</h1><h2 class=subtitle><time datetime=2020-04-14T00:00:00Z>April 14, 2020</time></h2></div></div></section><section class=section><div class=container><div class="content is-medium"><!doctype html><html xmlns=http://www.w3.org/1999/xhtml xmlns:x=http://www.texmacs.org/2002/extensions xmlns:m=http://www.w3.org/1998/Math/MathML><head><title>No title</title><meta content="TeXmacs 1.99.12" name=generator></meta><style type=text/css>body{text-align:justify}h5{display:inline;padding-right:1em}h6{display:inline;padding-right:1em}table{border-collapse:collapse}td{padding:.2em;vertical-align:baseline}dt{float:left;min-width:1.75em;text-align:right;padding-right:.75em;font-weight:700}dd{margin-left:2.5em}.subsup{display:inline;vertical-align:-.2em}.subsup td{padding:0;text-align:left}.fraction{display:inline;vertical-align:-.8em}.fraction td{padding:0;text-align:center}.wide{position:relative;margin-left:-.4em}.accent{position:relative;margin-left:-.4em;top:-.1em}.title-block{width:100%;text-align:center}.title-block p{margin:0}.compact-block p{margin-top:0;margin-bottom:0}.left-tab{text-align:left}.center-tab{text-align:center}.balloon-anchor{border-bottom:1px dotted #000;outline:none;cursor:help;position:relative}.balloon-anchor [hidden]{margin-left:-999em;position:absolute;display:none}.balloon-anchor: hover [hidden]{position:absolute;left:1em;top:2em;z-index:99;margin-left:0;width:500px;display:inline-block}.balloon-body{}.ornament{border-width:1px;border-style:solid;border-color:#000;display:inline-block;padding:.2em}.right-tab{float:right;position:relative;top:-1em}</style><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" language=javascript></script></head><body><h2 id=auto-1>1<span style=margin-left:1em></span>Introduction<span style=margin-left:1em></span></h2><p>Many days ago, during my discussion with my colleagues, I found out that
I only had intuitive explanation towards why we should pick the
parameters that maximize that probability over the data. But any
ill-sampled data would affect the effectiveness of this approach. For
example, for a distribution with high variance, it would easily lead to
samples that deviate from the mean. I realize I need a further
understanding to figure out why Maximum Likelihood Estimation (MLE)
works in practise.</p><table style=width:100%><tbody><tr><td style=text-align:center;padding-left:0;padding-right:0><img src=maximum_likelihood_estimation-1.png width=100%></img></td></tr><tr><td style=text-align:center;padding-left:0;padding-right:0;height:.5em></td></tr><tr><td style=text-align:center;padding-left:0;padding-right:0;padding-left:1.5em;padding-right:1.5em><p><font style="font-size: 84.1%"><p><b>Figure 1. </b><a id=auto-2></a>Suppose the samples I obtain is
biased, when sample size is limited, I can sample points that are
away from 0 if they follow blue curve.</p></font></p></td></tr></tbody></table><h2 id=auto-3>2<span style=margin-left:1em></span>What is MLE?<span style=margin-left:1em></span></h2><h3 id=auto-4>2.1<span style=margin-left:1em></span>A motivating example<span style=margin-left:1em></span></h3><p>Suppose we are given a series of observations of flipping coins and we
can safely assume that each time we flip a coin, we have \(p\) chance of
getting a head, and \(1 - p\) getting tails. The thing is we don't know
what value does \(p\) take (of course everyone would think it is 0.5,
but consider a biased coin). An easy way to estimate it is through the
patterns of observations, or how many times do we see heads and tails
showing up. Let \(X_n\) be the indicator of showing up heads, \(X_n =
1\), means head for the \(n\)-th time. Since the expectation</p><center>\(\displaystyle \mathbb{E} (X_1 + \cdots + X_n) = n p,\)</center><p>then we can just add them up and take the average to estimate \(p\),</p><center>\(\displaystyle \hat{p} = \frac{\mathbb{E} (X_1 + \cdots + X_n)}{n} .\)</center><p>Seems naive. But as MLE tells us, this actually works, not from the same
derivation of course :) The idea of inferencing parameters or
characteristics of probabilistic models goes a long way. Note that the
method I use here is entirely for building intuition, it is not a real
way of statistical inference (not suitable for other types of
distributions).</p><h3 id=auto-5>2.2<span style=margin-left:1em></span>Formal definition of MLE<span style=margin-left:1em></span></h3><p>Now, what is MLE [<a href=#bib-MaximumLikelihoodEstimation2020>1</a>]? Suppose we are given a group of
\(i.i.d.\) data sampled from some unknown distribution \(P\). Assume
that there exists a parametric family \(P_{\phi}\), such that \(P \in
P_{\phi}\), and \(\phi \in \Phi\), where \(\Phi\) is the parameter
space, usually a Euclidean space taking the form \(\mathbb{R}^d\). In
other words, we can find a \(\phi^{\ast} \in \Phi\), such that \(P =
P_{\phi^{\ast}}\) (note that we haven't defined what equality means for
distribution).</p><center>\(\displaystyle X_n \sim P_{\phi^{\ast}}\)</center><p>Usually, in continuous case, we would represent distribution
\(P_{\phi}\) with a probabilistic density function \(f_{\phi} (x)\).
Then as we can see, this function actually takes in two arguments, one
is parameter \(\phi\), another observation \(x\), which can be rewritten
as likelihood function if we know all the observations \(X_n\):</p><center>\(\displaystyle L (\phi |X_1, \ldots, X_n) = f_{\phi} (X_1, X_2, \ldots,
X_n) = f_{\phi} (X_1)
\cdots f_{\phi} (X_n)\)</center><p>Now, given all the parameters we can choose from \(\Phi\), what is the
most probable parameter we can choose that best fits these data? One
good candidate, is the parameter \(\phi\) can make this joint
distribution's PDF largest, or likelihood function largest. From here,
it becomes an optimization problem :) Many problems in machine
learning's first step is to convert the original problem into an
optimization problem. Be it an empirical tools like deep neural network,
SVM or probablisitic methods like Variational inference. So what MLE
does is that it will take these \(i.i.d.\) samples of \(P\), and find
the parameters by maximizing its likelihood function.</p><h3 id=auto-6>2.3<span style=margin-left:1em></span>Back to the original example<span style=margin-left:1em></span></h3><p>Consider our previous example, all we know is that it is distributed
according to a Bernoulli distribution, but we don't know value of \(p\).
We are trying to infer by first sampling a bunch of data, then estimate
that probability from the data.</p><center>\(\displaystyle P (X) = \left\{ \begin{array}{ll}
p, & X = 1\\
  1 -
      p, & X = 0
\end{array} \right. (\text{Bernoulli distribution})\)</center><p>Problem: given a series of \(i.i.d.\) samples \(x_1, x_2, \ldots, x_n\)
from \(P\), try to estimate the parameter \(p\) with MLE.</p><p>The joint probability (head \(\Rightarrow x_1 = 1\), tail \(\Rightarrow
x_1 = 0\)):</p><center>\begin{eqnarray*}
L (p|x_1, x_2, \ldots, x_n) & = & P (X_1 = x_1, X_2
      = x_2, \ldots, X_n = x_n
|p)\\
& = & \prod_{i = 1}^n p^{x_i} \cdot
(1 - p)^{1 - x_i}
\end{eqnarray*}</center><p>Now according to MLE:</p><center>\(\displaystyle p^{\ast} = \arg \max_{p \in [0, 1]} L (p|\boldsymbol{x})
.\)</center><p>Usually it is more convenient to transform it into logarithm:</p><center>\begin{eqnarray*}
l (p|\boldsymbol{x}) & = & \log (L
      (p|\boldsymbol{x}))\\
& = & \sum_{i = 1}^n x_i \cdot \log (p) + (1 -
x_i) \cdot \log (1 - p)\\
& = & (n \bar{x}) \cdot \log (p) + n (1 -
\bar{x}) \cdot \log (1 - p)
\end{eqnarray*}</center><p>If \(l\) is differentiable, then a necessary condition for \(l\) to
reach maximum is \(\frac{\partial l}{\partial p} = 0\):</p><center>\begin{eqnarray*}
\frac{\partial l}{\partial p} & = & 0\\
  \frac{n
      \bar{x}}{p} - \frac{n (1 - \bar{x})}{1 - p} & = & 0
\end{eqnarray*}
   </center>
<center>\(\displaystyle \Rightarrow p = \bar{x}\)</center><p>By MLE, we would estimate \(p\) by the \(\bar{x}\), which the proportion
of heads in the samples. To answer the question proposed at first, this
method is highly susceptible to the sampled data, if the data does not
capture the its underlying distribution (what does this mean?) well,
then it surely will not pick the best parameter. While this method may
be explained easily in intuition, it seems that we need additional tools
to guarantee, or to know when it can work. In other words, it raises a
few questions</p><h3 id=auto-7><a id=question-of-interest></a>2.4<span style=margin-left:1em></span>Questions to uncover<span style=margin-left:1em></span></h3><ul><li><p>Can it converge as the data sample size increase?</p></li><li><p>Under what circumstances will it converge to the true parameter?</p></li><li><p>How well can it approaximate the parameters? Any bounds around the
estimation?</p></li></ul><p>In section <a href=#section-3>3</a>, I will mainly address the first and second
questions and I will leave the third question for another time. These
questions come from the intuition given by the Law of Large Number
(LLN): if we have sufficient samples, some properties of the
distribution will almost surely be revealed. I think this is the very
core intuition of statistical analysis. Given a collection of data, be
it small or large, what can we know from the distribution that is
generating them.</p><p>Another important aspect of analysis is will some stochastic sequences
converge and how fast will they converge? This analysis usually guides
us to develop new algorithms or learn new insights of existing
algorithms. If we know what the limit is (the result converges, and
where it converges), we can be very confident that the algorithm we
devise will work, however impractical it may be (exponential sample size
with respect to variance or other metrics), because we can always take
more steps/iterations with the confidence that it will move towards the
desired target, i.e., it remains a nice-to-have property.</p><h2 id=auto-8><a id=section-3></a>3<span style=margin-left:1em></span>MLE analysis: why does it
work?<span style=margin-left:1em></span></h2><p>One important property of MLE is called <strong>consistency</strong>,
which states that, as the number of samples approach infinity, the
parameter estimation will converge to the true parameter in probability
(not for all distribution though, only works for the good ones). In the
following section, I will give out a few concepts to first build up the
intuition. After that, I will move on to more rigorous proof of MLE
consistency.</p><p><p><b>Definition <class style="font-style: normal">1</class>. </b><i>MLE is consistent
if:</i></p><p><i><p>Let \(\hat{\phi}\) be the estimated parameter given by MLE, and
\(\phi^{\ast}\) the true parameter,</p></i></p><p><i><center>\(\displaystyle \hat{\phi} \xrightarrow{p} \phi^{\ast} .\)</center></i></p></p><h3 id=auto-9>3.1<span style=margin-left:1em></span>Likelyhood function and connection to true
parameters<span style=margin-left:1em></span></h3><p>We have \(n\) \(i.i.d.\) random variables from \(\{ X_n \} \sim
P_{\phi^{\ast}}\).</p><center>\(\displaystyle l_n (\phi) = l (\phi |X_n) = \log (f_{\phi} (X_n)) .\)</center><p>and that</p><center>\(\displaystyle l (x, \phi) = \log (f_{\phi} (x))\)</center><p>\(l_n (\phi)\) is a random variable parameterized by \(\phi\), whose
average should converge to the expectation in probability according to
Weak Law of Large Number (WLLN):</p><center>\(\displaystyle \frac{1}{n} \sum_{i = 1}^n l_i (\phi) \xrightarrow{p}
E_{x \sim
P_{\phi^{\ast}}} [l (x, \phi)] .\)</center><p>Now, are there any connections between this rebranded likelihood
function and the true parameters that we are trying to inference? It
turns out lemma <a href=#lemma-1>2</a> gives us a cute connection.</p><p><p><b>Lemma <class style="font-style: normal">2</class>. </b><i><a id=lemma-1></a></i></p><p><i><center>\(\displaystyle E_{x \sim P_{\phi^{\ast}}} [l (x, \phi^{\ast})]
\geqslant E_{x \sim
P_{\phi^{\ast}}} [l (x, \phi)] .\)</center></i></p><p><i>for all \(\phi \in \Phi\).</i></p></p><p>The lemma <a href=#lemma-1>2</a> states that the true parameters are actually
the maximizer of this expectation of likelihood function. Hence, the
intuition behind the proof of MLE's consistency is that since</p><center>\(\displaystyle \frac{1}{n} \sum_{i = 1}^n l_i (\phi) \xrightarrow{p}
E_{x \sim
P_{\phi^{\ast}}} [l (x, \phi)]\)</center><p>and</p><center>\(\displaystyle \phi^{\ast} = \arg \max_{\phi \in \Phi} E_{x \sim
P_{\phi^{\ast}}} [l (x,
\phi)],\)</center>
<center>\(\displaystyle \hat{\phi} = \arg \max_{\phi \in \Phi} \frac{1}{n}
\sum_{i = 1}^n l_i (\phi) .\)</center><p>\(\hat{\phi}\) should be also close to \(\phi^{\ast}\) because we have
this two functions (w.r.t. \(\phi\)) stay close to each other in
parameter space, their maximizers should be close too. However, if there
are two maxima in \(E_{x \sim P_{\phi^{\ast}}} [l (x, \phi)]\),
\(\hat{\phi}\) can take two possible locations even if \(\)\(\frac{1}{n}
\sum_{i = 1}^n l_i (\phi) = E_{P_{\phi^{\ast}}} [l (\phi)]\) (maybe a
graph here). Or if there is an asymptotic that approaches
\(E_{P_{\phi^{\ast}}} [l (\phi)]\).</p><p>Therefore the first condition of ensuring consistency is as follows:</p><p><p><b>Definition <class style="font-style: normal">3</class>. </b><i>Identification
condition:</i></p><p><i></i></p><p><i><center>\(\displaystyle \phi \neq \phi^{\ast} \Leftrightarrow f (\cdot |
\phi) \neq f (\cdot |
\phi^{\ast}) .\)</center></i></p></p><p>The identification condition establishes that the log-likelihood has a
unique global maximum since there will be no parameter that can obscure
true parameter.</p><p></p><p>On the other hand, usually compactness is required, but it is only a
sufficient condition and not a necessary condition. Compactness implies
that the likelihood cannot approach the maximum value arbitrarily close
at some other point. In other words, the maximizer is only achievable
when it is on or close to \(\phi^{\ast}\).</p><p>Compactness can be replaced by some other conditions, such as</p><ul><li><p>both concavity of the log-likelihood function and compactness of
some (nonempty) upper level sets of the log-likelihood function, or</p></li><li><p>existence of a compact neighborhood \(N\) of \(\phi_0\) such that
outside of \(N\) the log-likelihood function is less than the
maximum by at least some \(\varepsilon > 0\).</p></li></ul><p style=margin-top:1em;margin-bottom:1em><b>Remark <class style="font-style: normal">4</class>. </b>Compactness is indeed a strong
condition regarding this proof, the original intention is to ban the
function from approaching global maximum by limit. Enforcing eompactness
no doubt makes the entire function's domain a closed subset (on
\(\mathbb{R}^n\) space), which is too strong for this proof.</p><p>However, to keep this post simple (also my poor knowledge), I will use
the stronger version.</p><h2 id=auto-10>4<span style=margin-left:1em></span>A simple proof<span style=margin-left:1em></span></h2><p><strong>Warning</strong>: this note does not intend to give the most
rigorous proof on MLE consistency due to my personal insufficency on
real analysis, and sufficient some conditions on MLE consistency, I
don't fully comprehend. This part is mostly just for fun.</p><p>I will start it off with a simple lemma on closed bounded continuous
function stating that if you have a sequence whose function evaluation
converges to a unique maximum, then this sequence will converge to
maximum achiever. This is really relevant to MLE consistency, if we
think of that problem as if two functions staying close together, then
their maximum achiever should stay close together as well.</p><p><p><b>Lemma <class style="font-style: normal">5</class>. </b><i><a id=lemma-2></a>Let \(\Theta\) be
a closed bounded subset of \(\mathbb{R}^n\), and let \(g : \Theta
\rightarrow \mathbb{R}\) be continuous. Assume that \(\theta^{\ast}\)
is the uniuqe maximizer of \(g\) over \(\Theta\). If \(\theta_n\) is a
sequence in \(\Theta\) satisfying \(g (\theta_n) \rightarrow g
(\theta^{\ast})\), then \(\theta_n \rightarrow \theta^{\ast}\).</i></p><p><i><p><b>Proof. </b>I wish to show that for \(\forall \varepsilon > 0\),
there exists \(N > 0\), such that when \(n > N\), \(\| \theta_n -
\theta^{\ast} \| < \varepsilon .\)</p></i></p><p><i>\(\Theta' = \{ \theta | \| \theta - \theta^{\ast} \| \geqslant
\varepsilon \}
\neq \varnothing\) for small enough \(\varepsilon\). If
\(\Theta = \{ \theta^{\ast} \}\), the conclusion is trivial. Only
consider \(\Theta \neq \{ \theta^{\ast} \}\), we can see that
\(\Theta'\) is closed and bounded. Using Weierstrass Theorem, we have
the maximum \(m\) in \(\Theta'\), and since \(\theta^{\ast}\) is the
unique maximizer in \(\Theta\), \(g (\theta^{\ast}) > m\). Since \(g
(\theta_n) \rightarrow g (\theta^{\ast})\), there exists \(N > 0\),
such that \(g (\theta_n) > m\), hence \(\theta_n \not\in \Theta'\),
which in turn proves that \(\| \theta_n - \theta^{\ast} \| <
\varepsilon\).</i></p></p><p>To utilize lemma <a href=#lemma-2>5</a>, we need a convergence sequence of \(g
(\phi_n) =\mathbb{E}_{x \sim P_{\phi^{\ast}}} [l (x, \phi_n)]
\rightarrow g
(\phi^{\ast})\). However, the original connection is not
on the same function, i.e., we have a function sequence that converge to
the expectation in probability and their repective maximum achiever
should thus converge if the conditions: identificaiton, unique maximum
as well as compactness are met.</p><p>First question I would ask is do we know that the maximum of two
functions converge? Because it is a necessary condition of the two
maximum achievers agree. So the question becomes, if the maximum of
function sequence</p><center>\(\displaystyle \sup_{\phi_1} \frac{1}{n} \sum_{i = 1}^n l_i (\phi_1)
\xrightarrow{p}
\sup_{\phi_2} \mathbb{E}_{x \sim P_{\phi^{\ast}}} [l (x,
\phi_2)]\)</center><p></p><p>converges to the target funciton or not.</p><p>The intuition of this proof is that if their maximums do not match, such
funciton sequence will not converge at least on these maximum points,
which means a conflict.</p><h3 id=auto-11>4.1<span style=margin-left:1em></span>A possible wrong approach<span style=margin-left:1em></span></h3><p>The following is my initial proof, which contains something I consider
weak of the proof, that is I cannot guarantee that I can locate the
maximizer of the probability convergent sequence \(\phi_1 = \arg
\max_{\phi} \lim_{n \rightarrow \infty} \frac{1}{n} \sum_{i =
1}^n l_i
(\phi)\). Anyway, I include this proof is to shed some lights on my
thinking process. Readers that don't care can skip this part.</p><p><p><b>Proof. </b>By Weierstrass Theorem, we can find maximizers in their
respective functions.</p><center>\(\displaystyle \phi_1 = \arg \max_{\phi} \left( \lim_{n \rightarrow
\infty} \frac{1}{n}
\sum_{i = 1}^n l_i (\phi) \right)\)</center><p>and</p><center>\(\displaystyle \phi^{\ast} = \arg \max_{\phi} \left( \mathbb{E}_{x
\sim P_{\phi^{\ast}}} [l
(x, \phi)] \right) .\)</center><p>Now, we plug it in</p><center>\(\displaystyle \frac{1}{n} \sum_{i = 1}^n l_i (\phi_1) = m_{1 n}\)</center><p>and</p><center>\(\displaystyle \frac{1}{n} \sum_{i = 1}^n l_i (\phi^{\ast}) = m_{2 n}
.\)</center><p>\(\mathbb{E}_{x \sim P^{\ast}} [l (x, \phi_1)] = g_1\).
\(\mathbb{E}_{x \sim P^{\ast}} [l (x, \phi^{\ast})] = g_2\), from the
convergence of \(\)\(\lim_{n \rightarrow \infty} \frac{1}{n} \sum_{i =
1}^n l_i (\phi)\), for \(\forall \varepsilon > 0\),</p><center>\(\displaystyle \lim_{n \rightarrow \infty} P (| m_{1 n} - g_1 | >
\varepsilon) = 0,\)</center>
<center>\(\displaystyle \lim_{n \rightarrow \infty} P (| m_{2 n} - g_2 | >
\varepsilon) = 0.\)</center><p>For any \(n\), \(m_{1 n} > m_{2 n}\), and \(g_2 > g_1\) (unique
maximizer).</p><center>\(\displaystyle \lim_{n \rightarrow \infty} P (m_{1 n} > m_{2 n}) = 1
\text{ and } \lim_{n
\rightarrow \infty} P (g_2 > g_1) = 1\)</center><p>Since \(1 \leqslant P (| m_{1 n} - g_1 | \leqslant \varepsilon)
\leqslant P (m_{1 n}
\leqslant \varepsilon + g_1 < g_2) = 1\) as \(n
\rightarrow \infty\) and for sufficient small \(\varepsilon\).</p><p>Similarly, \(1 \leqslant P (| m_{2 n} - g_2 | \leqslant \varepsilon)
\leqslant P (g_2
\leqslant \varepsilon + m_{2 n} < m_{1 n}) = 1\) as
\(n \rightarrow \infty\) and for sufficient small \(\varepsilon\).</p><p>We thus have, \(P (g_2 < m_{1 n}) = 1\) and \(P (m_{1 n} < g_2) = 1\),
which raises a conflict.</p><p></p><p>Therefore, \(m_1 = g_2\), i.e., their maximum should agree. We then
use a simple triangular inequality to complete the proof.</p><p>Since \(P\) is monotove relative to set containment, we have</p><center>\begin{eqnarray*}
P \left( \left| \mathbb{E}_{x \sim
P_{\phi^{\ast}}} [l (x, \phi_n)]
-\mathbb{E}_{x \sim
P_{\phi^{\ast}}} [l (x, \phi^{\ast})] \right| \geqslant
\varepsilon
\right) & \leqslant & P \left( \left| \mathbb{E}_{x \sim
P_{\phi^{\ast}}} [l (x, \phi_n)] - \frac{1}{n} \sum_{i = 1}^n l_i
(\phi_n)
\right| + \left| \mathbb{E}_{x \sim P_{\phi^{\ast}}} [l (x,
\phi^{\ast})] -
\frac{1}{n} \sum_{i = 1}^n l_i (\phi_n) \right| >
\varepsilon \right)\\
& \leqslant & P \left( \left| \mathbb{E}_{x
\sim P_{\phi^{\ast}}} [l (x,
\phi_n)] - \frac{1}{n} \sum_{i = 1}^n
l_i (\phi_n) \right| \geqslant
\frac{1}{2} \varepsilon \right) + P
\left( \left| \mathbb{E}_{x \sim
P_{\phi^{\ast}}} [l (x,
\phi^{\ast})] - \frac{1}{n} \sum_{i = 1}^n l_i
(\phi_n) \right|
\geqslant \frac{1}{2} \varepsilon \right) .\\
& = &
        0
\end{eqnarray*}
  </center><p>Hence \(\phi_n\) is a sequence such that \(g (\phi_n) \rightarrow g
(\phi^{\ast})\), with lemma <a href=#lemma-2>5</a>, we know that \(\phi_n
\rightarrow \phi^{\ast}\).</p></p><p>Here is another proof, which uses a lemma <a href=https://math.stackexchange.com/questions/246015/supremum-of-the-difference-of-two-functions>here</a> and much
shorter. Usually it is much easier to verify the correctness of short
proof.</p><p><p><b>Proof.</b></p><p><b>Lemma <class style="font-style: normal">6</class>. </b><i></i></p><p><i></i></p><p><i><center>\(\displaystyle | \sup_x f (x) - \sup_x g (x) | \leqslant \sup_x | f
(x) - g (x) | .\)</center></i></p><p>Now things become simple, no need to find the maximizer!</p><p>Since \(P\) is monotove relative to set containment, we have</p><center>\(\displaystyle 1 \geqslant P \left( \left| \sup_{\phi} \frac{1}{n}
\sum_{i = 1}^n l_i (\phi)
- \sup_{\phi} \mathbb{E}_{x \sim
P_{\phi^{\ast}}} [l (x, \phi)] \right| <
\varepsilon \right) \geqslant
P \left( \sup_{\phi} \left| \frac{1}{n} \sum_{i
= 1}^n l_i (\phi)
-\mathbb{E}_{x \sim P_{\phi^{\ast}}} [l (x, \phi)] \right|
<
\varepsilon \right) \rightarrow 1.\)</center><p>Now let \(n \rightarrow \infty\). We can conclude that</p><center>\(\displaystyle \sup_{\phi} \frac{1}{n} \sum_{i = 1}^n l_i (\phi)
\xrightarrow{p} \sup_{\phi}
\mathbb{E}_{x \sim P_{\phi^{\ast}}} [l (x,
\phi)] .\)</center><p>Coming back to the original problem, let</p><center>\(\displaystyle \phi_n = \arg \max_{\phi} \frac{1}{n} \sum_{i = 1}^n
l_i (\phi) \text{ and }
\phi^{\ast} = \arg \max_{\phi} \mathbb{E}_{x
\sim P_{\phi^{\ast}}} [l (x,
\phi)] ._{}\)</center><p>For \(\forall \varepsilon > 0\),</p><center>\begin{eqnarray*}
P \left( \left| \mathbb{E}_{x \sim
P_{\phi^{\ast}}} [l (x, \phi_n)]
-\mathbb{E}_{x \sim
P_{\phi^{\ast}}} [l (x, \phi^{\ast})] \right| \geqslant
\varepsilon
\right) & \leqslant & P \left( \left| \mathbb{E}_{x \sim
P_{\phi^{\ast}}} [l (x, \phi_n)] - \frac{1}{n} \sum_{i = 1}^n l_i
(\phi_n)
\right| + \left| \mathbb{E}_{x \sim P_{\phi^{\ast}}} [l (x,
\phi^{\ast})] -
\frac{1}{n} \sum_{i = 1}^n l_i (\phi_n) \right|
\geqslant \varepsilon
\right)\\
& \leqslant & P \left( \left|
     \mathbb{E}_{x \sim P_{\phi^{\ast}}} [l (x,
\phi_n)] - \frac{1}{n}
\sum_{i = 1}^n l_i (\phi_n) \right| \geqslant
\frac{1}{2}
\varepsilon \right) + P \left( \left| \mathbb{E}_{x \sim
P_{\phi^{\ast}}} [l (x, \phi^{\ast})] - \frac{1}{n} \sum_{i = 1}^n
l_i
(\phi_n) \right| \geqslant \frac{1}{2} \varepsilon \right) .\\
& \leqslant & P \left( \sup_{\phi} \left| \mathbb{E}_{x \sim
P_{\phi^{\ast}}} [l (x, \phi)] - \frac{1}{n} \sum_{i = 1}^n l_i
(\phi)
\right| \geqslant \frac{1}{2} \varepsilon \right) + P \left(
\left|
\sup_{\phi} \mathbb{E}_{x \sim P_{\phi^{\ast}}} [l (x, \phi)]
- \sup_{\phi}
\frac{1}{n} \sum_{i = 1}^n l_i (\phi) \right|
\geqslant \frac{1}{2}
\varepsilon \right)\\
& \rightarrow & 0
        \quad \operatorname{as} \quad n \rightarrow \infty
\end{eqnarray*}</center><p>Now, we know that</p><center>\(\displaystyle \mathbb{E}_{x \sim P_{\phi^{\ast}}} [l (x, \phi_n)]
\xrightarrow{p}
\mathbb{E}_{x \sim P_{\phi^{\ast}}} [l (x,
\phi^{\ast})] .\)</center><p>Combined with lemma <a href=#lemma-2>5</a>, (may have to generalize to
probability convergent form, will do it in future :) ), we have</p><center>\(\displaystyle \phi_n \xrightarrow{p} \phi^{\ast} .\)</center></p><h2 id=auto-12>5<span style=margin-left:1em></span>Conclusion<span style=margin-left:1em></span></h2><p>Back to the original questions posted in section <a href=#question-of-interest>2.4</a>:</p><p>It will converge to the desired parameter with high probability if its
PDF satisfies certain conditions. As for the third question, I realize I
need to learn more on Fisher information or how well-defined should the
PDF be, in order to have good convergence speed. More on that in another
post.</p><p>As we can see, something that looks so natural and seemingly simple,
takes a lot of efforts to prove. But in the end, our intuition prevails.
It is indeed a good candidate to pick out the most likely parameters,
even a child knows without rigorous proof. As you might notice, I use
the word &ldquo;intuition&rdquo; in my post extensively, because I think
that has been one of the missing pieces in my study of mathematics.
Lately, I find out the importance of intuition and I would like to write
a small follow-up post about why intuition is critical in mathematics.</p><p></p><h2 id=auto-13>Bibliography<span style=margin-left:1em></span></h2><div style=text-indent:0><div class=compact-block><font style="font-size: 84.0%"><dl><p><strong>[1]</strong> <a id=bib-MaximumLikelihoodEstimation2020></a>Maximum likelihood estimation.
00003 Page Version ID: 950319146.</p></dl></font></div></div><p>http://math.caltech.edu/~2016-17/2term/ma003/Notes/MLEConsistency.pdf</p><p></p></body></html></div></div></section><footer class=footer><div class="content has-text-centered"><p><a href=https://github.com/orf/bare-hugo-theme target=_blank>Bare Hugo theme.</a></p></div></footer><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','Ua-139857559-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script></body></html>